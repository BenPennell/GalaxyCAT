{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SITELLE GalaxyCAT\n",
    "#### SITELLE Galaxy Cluster Analysis Tools\n",
    "Ben Pennell\n",
    "\n",
    "\n",
    "#### What is this?\n",
    "\n",
    "\n",
    "This is extremely fragile code, with much dependence on the specific structure and file organization in the datacubes and on my machine.\n",
    "\n",
    "What it does it uses 10 datacubes of galaxy clusters at z~0.23 from the SITELLE instrument aboard the CFHT, and it uses other code and data analysis that's already been done in addition to new data manipulation to create plots and visualizations to understand what is happening in these clusters.\n",
    "\n",
    "Everything is held within a function, since some of these functions are powerful and can modify things such as fits header files, I don't want to accidentally run something that makes an irreversible change. Scroll all the way to the bottom, and there is a code block that you should use to run the functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run these cells first"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 0.322 #arcsec/pix\n",
    "SPEED_C = 2.998e5 # km/s\n",
    "\n",
    "CUBES = ['A1736C', 'A2219C', 'A2390C', 'A2390NW', 'A2390SE', 'A2465C', 'A2465SW', 'A2465NE', 'RXJ2129C', 'RXJ2129S', 'RXJ2129W', 'ZWCL0823']\n",
    "CUBES_REDUCED = [\"A1736\", \"A2219\", \"A2390\", \"A2465\", \"RXJ21\", \"ZWCL0\"]\n",
    "REDSHIFTS = [0.2323, 0.2257, 0.228, 0.228, 0.228, 0.245, 0.245, 0.245, 0.2336, 0.2336, 0.2336, 0.2261]\n",
    "REDSHIFTS_REDUCED = [0.2323, 0.2257, 0.228, 0.245, 0.2336, 0.2261]\n",
    "R200S = [1830, 2241, 1930, 1930, 1930, \"N/A\", 1240, 1240, 1841, 1841, 1841, 1575]\n",
    "DISPERSIONS = [1358, 1332, 1095, 1095, 1095, \"N/A\", 763, 722, 879, 879, 879, 671]\n",
    "R200S_REDUCED = [1830, 2241, 1930, 1210, 1240, 1841, 1575] # IN KPC!!!!!\n",
    "DISPERSIONS_REDUCED = [1358, 1332, 1095, 763, 722, 879, 671]\n",
    "BCGS = {\"A1736\":[(203.8337946, 41.0011150)], \n",
    "        \"A2219\":[(250.08, 46.71)], \n",
    "        \"A2390\":[(328.403512, 17.695440)], \n",
    "        \"A2465\":[(339.918680, -5.723983), (339.852272, -5.788233)], \n",
    "        \"RXJ21\":[(322.41625, 0.08916667)], \n",
    "        \"ZWCL0\":[(126.49090442, 4.24659197)]}\n",
    "\n",
    "CATALOGUE_KPC_PATH = \"catalogue_dist_kpc.txt\"\n",
    "CATALOGUE_PHASE_PATH = \"Phase_Diagram_Catalogue.txt\"\n",
    "FIELD_INDEX = 0\n",
    "NAME_INDEX = 1\n",
    "XPOS_INDEX = 2\n",
    "YPOS_INDEX = 3\n",
    "FLAG_INDEX = 5\n",
    "HAZ_INDEX = 6\n",
    "HASN_INDEX = 8\n",
    "OTSN_INDEX = 11\n",
    "KPC_INDEX = 15\n",
    "PVEL_INDEX = 16 # Peculiar Velocity\n",
    "DIST_INDEX = 17 # R / R200 distance\n",
    "\n",
    "FITS_PATH = \"E:\\AstroResearch\\SITELLE\\{}\\{}.deep_frame.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWCS(field):\n",
    "    hdul = fits.open(FITS_PATH.format(field, field), mode='readonly', memmap=False)\n",
    "    header=hdul[0].header\n",
    "    wcs=WCS(header)\n",
    "    hdul.close()\n",
    "\n",
    "    return wcs\n",
    "\n",
    "def radecToPix(radec_coords, field):\n",
    "    '''\n",
    "        radec_coords (tuple of floats): (ra, dec) in degrees\n",
    "        field (String): name of field (eg. \"A2390C\")\n",
    "    '''\n",
    " \n",
    "    wcs = getWCS(field)\n",
    "        \n",
    "    coords = SkyCoord(ra=radec_coords[0]*u.degree, dec=radec_coords[1]*u.degree, frame='icrs')\n",
    "    x, y = wcs.world_to_pixel(coords)\n",
    "    return (x, y)\n",
    "\n",
    "def pixToRadec(pix_coords, field):\n",
    "    wcs = getWCS(field)\n",
    "    location = wcs.pixel_to_world(pix_coords[0], pix_coords[1])\n",
    "    return (location.ra.deg, location.dec.deg)\n",
    "\n",
    "def kpcToPix(distance_kpc, field):\n",
    "    '''\n",
    "        Converts a transverse distance in kpc to a distance in pixels\n",
    "        Takes in the field, and the function will grab the redshift for it\n",
    "        Uses astropy universe for a good approximation\n",
    "    '''\n",
    "    \n",
    "    universe = FlatLambdaCDM(H0=70, Om0=0.3)\n",
    "\n",
    "    angular_distance = universe.angular_diameter_distance(REDSHIFTS_REDUCED[CUBES_REDUCED.index(field[:5])]) # Mpc / rad\n",
    "\n",
    "    angular_distance = angular_distance * 1000 # kpc / rad\n",
    "\n",
    "    angular_distance = angular_distance / (180 / np.pi) / 3600 # kpc / arcsec\n",
    "\n",
    "    angular_size = distance_kpc * RESOLUTION # arcsec\n",
    "\n",
    "    distance_pix = angular_distance * angular_size # kpc\n",
    "    \n",
    "    return distance_pix.value\n",
    "\n",
    "def radTokpc(distance_rad, field):\n",
    "    redshift = REDSHIFTS_REDUCED[CUBES_REDUCED.index(field[:5])]\n",
    "\n",
    "    universe = FlatLambdaCDM(H0=70, Om0=0.3)\n",
    "\n",
    "    angular_distance = universe.angular_diameter_distance(redshift) # Mpc / rad\n",
    "\n",
    "    angular_distance = angular_distance * 1000 # kpc / rad\n",
    "\n",
    "    size = angular_distance * distance_rad # kpc\n",
    "\n",
    "    return size.value\n",
    "\n",
    "def kpcToRad(distance_kpc, field):\n",
    "    redshift = REDSHIFTS_REDUCED[CUBES_REDUCED.index(field[:5])]\n",
    "\n",
    "    universe = FlatLambdaCDM(H0=70, Om0=0.3)\n",
    "\n",
    "    angular_distance = universe.angular_diameter_distance(redshift) # Mpc / rad\n",
    "\n",
    "    angular_distance = angular_distance * 1000 # kpc / rad\n",
    "\n",
    "    size = distance_kpc / angular_distance # rad\n",
    "\n",
    "    return size.value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Phase Diagrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a multistep process\n",
    "1. For each galaxy, determine the distance to nearest BCG\n",
    "    1.1. Determine distance to BCG in radians\n",
    "    1.2. Convert distance to kpc\n",
    "    1.3. for A2465C, with two BCGs, use distance to closest BCG\n",
    "2. Calculate r/r_200 using this distance in kpc and cluster r_200\n",
    "3. Calculate vpec using galaxy velocity dispersion and relative redshift of galaxy\n",
    "4. Append the rrel and vpec into new catalogue: Phase_Diagram_catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_distance(field, x_1, y_1, BCG_ra, BCG_dec, name=None):\n",
    "    # x_1, y_1 are the galaxy\n",
    "\n",
    "    wcs = getWCS(field)\n",
    "\n",
    "    target_1 = wcs.pixel_to_world(x_1, y_1)\n",
    "\n",
    "    # ra, dec\n",
    "    dra = target_1.ra.deg - BCG_ra\n",
    "    ddec = target_1.dec.deg - BCG_dec\n",
    "\n",
    "    angle = np.sqrt((dra * np.cos(target_1.dec.rad))**2 + (ddec)**2) # THIS IS THE FORMULA\n",
    "    #if(field == \"A2390NW\"):\n",
    "        #print(\"{}: {},{} - {},{} - {},{}: {}\".format(name, BCG_ra, BCG_dec, x_1, y_1, target_1.ra.deg, target_1.dec.deg, angle * 60))\n",
    "    return np.radians(angle)\n",
    "    \n",
    "###########################################################\n",
    "\n",
    "def determine_distance_BCG(field, x_1, y_1, returnBCG=False, set_BCG=None, name=None):\n",
    "    angles = []\n",
    "    field_bcgs = []\n",
    "    if set_BCG is not None:\n",
    "        field_bcgs = set_BCG\n",
    "    else:\n",
    "        field_bcgs = BCGS[field[:5]]\n",
    "\n",
    "    for field_bcg in field_bcgs:\n",
    "        angles.append(determine_distance(field, x_1, y_1, field_bcg[0], field_bcg[1], name=name))\n",
    "\n",
    "    if returnBCG:\n",
    "        # THIS IS THE OPTIONAL RETURN THAT INSTEAD RETURNS WHICH BCG WAS USED\n",
    "        # This is used to determine which of multiple BCGs is closer in A2465\n",
    "        minvalue = np.min(angles)\n",
    "        index = angles.index(minvalue)\n",
    "        return index\n",
    "        \n",
    "    return np.min(angles)\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def determine_A2465_cluster(x, y):\n",
    "    bcg = determine_distance_BCG(\"A2465C\", x, y, returnBCG=True, set_BCG=BCGS[\"A2465\"])\n",
    "\n",
    "    if bcg == 0:\n",
    "        return \"NE\"\n",
    "    elif bcg == 1:\n",
    "        return \"SW\"\n",
    "    else:\n",
    "        print(\"what?\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kpc_catalogue():\n",
    "    catalogue = open(\"Catalogue.txt\", \"r\")\n",
    "    lines = catalogue.readlines()\n",
    "    catalogue.close()\n",
    "\n",
    "    newlines = lines.pop(0)[:-1] + \" dist_kpc_BCG\"\n",
    "    for line in lines:\n",
    "        elements = line.split(\" \")\n",
    "\n",
    "        field = elements[FIELD_INDEX]\n",
    "        name = elements[NAME_INDEX]\n",
    "        xpos = float(elements[XPOS_INDEX])\n",
    "        ypos = float(elements[YPOS_INDEX])\n",
    "\n",
    "        angular_sep = determine_distance_BCG(field, xpos, ypos, name=name)\n",
    "        kpc_sep = radTokpc(angular_sep, field)\n",
    "\n",
    "        newlines = newlines + \"\\n\" + line[:-1] + \" \" + str(kpc_sep)\n",
    "\n",
    "    outfile = open(\"catalogue_dist_kpc.txt\", \"w\")\n",
    "    outfile.write(newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePhaseDiagram(flag_cutoff=0, hasn_cutoff=0, use_abs=False, outfile_name=\"Phase_Diagram_Catalogue\"):\n",
    "    infile = open(\"catalogue_dist_kpc.txt\", \"r\")\n",
    "    lines = infile.readlines()\n",
    "    firstline = lines.pop(0)\n",
    "    infile.close()\n",
    "\n",
    "    outfile_path = \"{}.txt\".format(outfile_name)\n",
    "    outfile_data = firstline[:-1] + \" pvel dist\\n\"\n",
    "\n",
    "    for line in lines:\n",
    "        split_line = line.split(\" \")\n",
    "        field = split_line[FIELD_INDEX]\n",
    "        flag = float(split_line[FLAG_INDEX])\n",
    "        haSN = float(split_line[HASN_INDEX])\n",
    "\n",
    "        if haSN > hasn_cutoff: # Making sure it's a good ha detection, since the catalogue also has far objects\n",
    "            if flag >= flag_cutoff:\n",
    "                dist_kpc = float(split_line[KPC_INDEX])\n",
    "                redshift_ha = float(split_line[HAZ_INDEX])\n",
    "\n",
    "                field_index = 0\n",
    "\n",
    "                # A2465 is goofy because it's a merging cluster. We have to do some funky maneuvering to figure out which\n",
    "                # While also making sure the regular clusters still work normally\n",
    "                if field == \"A2465C\":\n",
    "                    # In this case, we need to split it into A2465NE and A2465SW (index 3 and 4)\n",
    "                    bcg = determine_A2465_cluster(float(split_line[XPOS_INDEX]), float(split_line[YPOS_INDEX]))\n",
    "                    if bcg == \"NE\":\n",
    "                        field_index = 3\n",
    "                    elif bcg == \"SW\":\n",
    "                        field_index = 4 \n",
    "                elif field == \"A2465NE\":\n",
    "                    field_index = 3\n",
    "                elif field == \"A2465SW\":\n",
    "                    field_index = 4\n",
    "                else:\n",
    "                    field_index = CUBES_REDUCED.index(field[:5])\n",
    "                \n",
    "                field_redshift = REDSHIFTS_REDUCED[field_index]\n",
    "                field_r200 = R200S_REDUCED[field_index]\n",
    "                field_dispersion = DISPERSIONS_REDUCED[field_index]\n",
    "\n",
    "                distance_magnitude = dist_kpc / field_r200\n",
    "                velocity_magnitude = (redshift_ha - field_redshift) * SPEED_C / field_dispersion / (1 + redshift_ha)\n",
    "\n",
    "                if use_abs: velocity_magnitude = abs(velocity_magnitude)\n",
    "\n",
    "                outfile_data = outfile_data + line[:-1] + \" \" + str(velocity_magnitude) + \" \" + str(distance_magnitude) + \"\\n\"\n",
    "\n",
    "    outfile = open(outfile_path, \"w\")\n",
    "    outfile.write(outfile_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing Phase Diagrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### phaseDiagramByFlag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phaseDiagramByFlag():\n",
    "    '''\n",
    "        This function takes in the catalogue with peculiar velocity and relative distances\n",
    "        And creates a phase diagram where each flag has different colours\n",
    "    '''\n",
    "\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    dists_by_flag = [[], [], [], []] #0, 1, 2, 3\n",
    "    pvels_by_flag = [[], [], [], []]\n",
    "\n",
    "    for datapoint in data:\n",
    "        dist = float(datapoint[DIST_INDEX])\n",
    "        pvel = float(datapoint[PVEL_INDEX])\n",
    "        # There are just a couple objects that never have a flag for some reason, and they'll be ignored\n",
    "        try:\n",
    "            flag = int(datapoint[FLAG_INDEX])\n",
    "            dists_by_flag[flag].append(dist)\n",
    "            pvels_by_flag[flag].append(pvel)\n",
    "        except:\n",
    "            print(\"Failure: {}, {}\".format(datapoint[0], datapoint[1]))\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(4):\n",
    "        plt.scatter(dists_by_flag[i], pvels_by_flag[i], alpha=0.6, label=\"Flag = {}\".format(i))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Phase Diagram By Flag For All Fields\", fontsize=20)\n",
    "    plt.xlabel(\"$R_{obj}/R_{200}$\", fontsize=18)\n",
    "    plt.ylabel(\"$(v_{obj} - v_{0})/σ_{v}$\", fontsize=18)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### phaseDiagramByField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phaseDiagramByField(separate=False):\n",
    "    '''\n",
    "        This function takes in the catalogue with peculiar velocity and relative distances\n",
    "        And creates a phase diagram where each field has different colours\n",
    "\n",
    "        separate=False (boolean): whether to draw them in separate images are all on top of each other\n",
    "    '''\n",
    "\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    dists_by_flag = [[], [], [], [], [], []] # Each cluster\n",
    "    pvels_by_flag = [[], [], [], [], [], []]\n",
    "\n",
    "    for object in data:\n",
    "        dist = float(object[DIST_INDEX])\n",
    "        pvel = float(object[PVEL_INDEX])\n",
    "        field = object[FIELD_INDEX]\n",
    "        index = CUBES_REDUCED.index(field[:5])\n",
    "\n",
    "        dists_by_flag[index].append(dist)\n",
    "        pvels_by_flag[index].append(pvel)\n",
    "\n",
    "    if not separate:\n",
    "        plt.figure()\n",
    "    \n",
    "    for i in range(len(CUBES_REDUCED)):\n",
    "        if separate:\n",
    "            plt.figure()\n",
    "            plt.scatter(dists_by_flag[i], pvels_by_flag[i])\n",
    "            plt.title(\"Phase Diagram for {}\".format(CUBES_REDUCED[i]), fontsize=20)\n",
    "            plt.xlabel(\"$R_{obj}/R_{200}$\", fontsize=18)\n",
    "            plt.ylabel(\"$(v_{obj} - v_{0})/σ_{v}$\", fontsize=18)\n",
    "        else:\n",
    "            plt.scatter(dists_by_flag[i], pvels_by_flag[i], alpha=0.6, label=\"Field = {}\".format(CUBES_REDUCED[i]))\n",
    "    \n",
    "    if not separate:\n",
    "        plt.legend()\n",
    "        plt.title(\"Phase Diagram By Field\", fontsize=20)\n",
    "        plt.xlabel(\"$R_{obj}/R_{200}$\", fontsize=18)\n",
    "        plt.ylabel(\"$(v_{obj} - v_{0})/σ_{v}$\", fontsize=18)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### phaseDiagramBySN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phaseDiagramBySN(groupCount=4):\n",
    "    '''\n",
    "        Creates phase diagrams depending on Ha and OIII signal to noise ratios\n",
    "    '''\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    SNs = [[],[]] # Ha, OIII\n",
    "    phase = [[],[]] # peculiar velocity, relative distance\n",
    "\n",
    "\n",
    "    for i, object in enumerate(data):\n",
    "        SNs[0].append(float(object[HASN_INDEX]))\n",
    "        SNs[1].append(float(object[OTSN_INDEX]))\n",
    "\n",
    "        phase[0].append(float(object[PVEL_INDEX]))\n",
    "        phase[1].append(float(object[DIST_INDEX]))\n",
    "    \n",
    "    for i, template in enumerate([\"Hα SN\", \"OIII SN\"]):\n",
    "        plt.figure()\n",
    "        SNRatios = SNs[i]\n",
    "        for j in range(groupCount):\n",
    "            cutoff_lower = j / groupCount * 100\n",
    "            cutoff_upper = (j + 1) / groupCount * 100\n",
    "\n",
    "            peculiar_velocities = []\n",
    "            relative_distances = []\n",
    "\n",
    "            for k, ratio in enumerate(SNRatios):\n",
    "                if ratio <= np.percentile(SNRatios, cutoff_upper) and ratio > np.percentile(SNRatios, cutoff_lower):\n",
    "                    vels = phase[0]\n",
    "                    dists = phase[1]\n",
    "\n",
    "                    peculiar_velocities.append(vels[k])\n",
    "                    relative_distances.append(dists[k])\n",
    "        \n",
    "            plt.scatter(relative_distances, peculiar_velocities, alpha=0.6, label=\"{} to {} Percentile\".format(int(cutoff_lower), int(cutoff_upper)))\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.title(\"Phase Diagram By {}\".format(template), fontsize=20)\n",
    "        plt.xlabel(\"$R_{obj}/R_{200}$\", fontsize=18)\n",
    "        plt.ylabel(\"$(v_{obj} - v_{0})/σ_{v}$\", fontsize=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### phaseDiagramBySNMagnitude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phaseDiagramBySNMagnitude(draw_plots=True, return_values=False, return_indices=False):\n",
    "    '''\n",
    "        This creates a regular phase diagram but removes any object with a higher OIII S/N than Hα S/N and plots them seperately\n",
    "    '''\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "    pvels_outlier = []\n",
    "    dists_outlier = []\n",
    "    pvels = []\n",
    "    dists = []\n",
    "\n",
    "    indices = []\n",
    "\n",
    "    for i, object in enumerate(data):\n",
    "        SN_Ha = float(object[HASN_INDEX])\n",
    "        SN_OIII = float(object[OTSN_INDEX])\n",
    "\n",
    "        if SN_Ha < SN_OIII:\n",
    "            pvels_outlier.append(float(object[PVEL_INDEX]))\n",
    "            dists_outlier.append(float(object[DIST_INDEX]))\n",
    "\n",
    "            indices.append(i)\n",
    "        else:\n",
    "            pvels.append(float(object[PVEL_INDEX]))\n",
    "            dists.append(float(object[DIST_INDEX]))\n",
    "        \n",
    "\n",
    "    if return_values:\n",
    "        return (dists, pvels), (dists_outlier, pvels_outlier)\n",
    "    \n",
    "    if return_indices:\n",
    "        return indices\n",
    "\n",
    "    if draw_plots:\n",
    "        plt.figure()\n",
    "        plt.scatter(dists, pvels, alpha=0.6, label=\"Higher Ha S/N\")\n",
    "        plt.scatter(dists_outlier, pvels_outlier, alpha=0.6, label=\"Higher OIII S/N\")    \n",
    "        plt.legend()\n",
    "        plt.title(\"Phase Diagram Separating High and Low Ha S/N\", fontsize=20)\n",
    "        plt.xlabel(\"$R_{obj}/R_{200}$\", fontsize=18)\n",
    "        plt.ylabel(\"$(v_{obj} - v_{0})/σ_{v}$\", fontsize=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distributionByVpec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributionByVpec(slice_size=0.2):\n",
    "    '''\n",
    "        This function takes the phase diagram, creates vertical slices and determines relative ratios\n",
    "        of OIII and Hα preferred object in each slice to see how the OIII objects are distributed\n",
    "        From the function phaseDiagramBySNMagnitude\n",
    "    '''\n",
    "    \n",
    "    regulars, outliers = phaseDiagramBySNMagnitude(draw_plots=False, return_values=True)\n",
    "    \n",
    "    regular_dists = regulars[0]\n",
    "    outlier_dists = outliers[0]\n",
    "    \n",
    "    regular_bucket = []\n",
    "    outlier_bucket = []\n",
    "    \n",
    "    \n",
    "    for dist in regular_dists:\n",
    "        regular_bucket.append(int(dist / slice_size))\n",
    "    \n",
    "    for dist in outlier_dists:\n",
    "        outlier_bucket.append(int(dist / slice_size))\n",
    "    \n",
    "    regular_bucket = np.array(regular_bucket)\n",
    "    outlier_bucket = np.array(outlier_bucket)\n",
    "    \n",
    "    buckets = []\n",
    "    ratios = []\n",
    "    \n",
    "    for i in range(np.max([np.max(regular_bucket), np.max(outlier_bucket)])):\n",
    "        buckets.append((i + 0.5) * slice_size)\n",
    "        regular_bucket_i = regular_bucket[regular_bucket==i]\n",
    "        outlier_bucket_i = outlier_bucket[outlier_bucket==i]\n",
    "        \n",
    "        denominator = 1\n",
    "        if len(regular_bucket_i) != 0:\n",
    "            denominator = len(regular_bucket_i)\n",
    "\n",
    "        numerator = 0\n",
    "        if len(outlier_bucket_i) != 0:\n",
    "            numerator = len(outlier_bucket_i)\n",
    "            \n",
    "        ratio = (numerator/denominator)\n",
    "        ratios.append(ratio)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(buckets, ratios)\n",
    "    plt.title(\"Ratio of OIII to Hα preference in phase diagram with buckets={}\".format(slice_size), fontsize=20)\n",
    "    plt.xlabel(\"$R_{obj}/R_{200}$\", fontsize=18)\n",
    "    plt.ylabel(\"$N_{OIII}/N_{Hα}$\", fontsize=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Ascension / Declination Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### radecPlot()\n",
    "Right ascension/declination plots for every object in every cluster\n",
    "\n",
    "Run this cell before running any of the others. All other ra/dec plots inherit from this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radecPlot(draw_plots=True, return_field=None):\n",
    "    '''\n",
    "        This takes every object in the catalogue and plots their ra/dec position\n",
    "        Of course, all the values in the catalogue are in x,y so WCS must be use to get coordinates\n",
    "        This will handle every field at once, and it does this through a goofy mechanism:\n",
    "        There is a CUBE_REDUCED array of each field's first five characters\n",
    "        the index of the field in that array implies the index in the RA_values and Dec_values array\n",
    "\n",
    "        draw_plots (boolean): whether to make the plot or not. Default=True\n",
    "        return_field (String): which reduced field to return, (eg. \"A2390\" or \"RXJ21\")\n",
    "    '''\n",
    "\n",
    "    ra_values = [[],[],[],[],[],[]]\n",
    "    dec_values = [[],[],[],[],[],[]]\n",
    "\n",
    "    field_indices = []\n",
    "\n",
    "    data = np.loadtxt(CATALOGUE_KPC_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        # Determine RA and Dec for each object in the catalogue, line by line\n",
    "        field = line[FIELD_INDEX]\n",
    "        xPos = float(line[XPOS_INDEX])\n",
    "        yPos = float(line[YPOS_INDEX])\n",
    "\n",
    "        wcs = getWCS(field)\n",
    "\n",
    "        position = wcs.pixel_to_world(xPos, yPos)\n",
    "\n",
    "        ra_value = position.ra.deg\n",
    "        dec_value = position.dec.deg\n",
    "\n",
    "        field_index = CUBES_REDUCED.index(field[:5])\n",
    "\n",
    "        ra_values[field_index].append(ra_value)\n",
    "        dec_values[field_index].append(dec_value)\n",
    "\n",
    "        if return_field is not None:\n",
    "            if field_index == CUBES_REDUCED.index(return_field[:5]):\n",
    "                field_indices.append(i) \n",
    "    \n",
    "    if draw_plots:\n",
    "        for i in range(len(CUBES_REDUCED)):\n",
    "            # Draw each plot and save them\n",
    "            plt.figure()\n",
    "            plt.scatter(dec_values[i], ra_values[i])\n",
    "            plt.title(\"Celestial Coordinates of Objects in {}\".format(CUBES_REDUCED[i]))\n",
    "            plt.xlabel(\"Declination (degrees)\")\n",
    "            plt.ylabel(\"Right Ascension (degrees)\")\n",
    "    \n",
    "    if return_field is not None:\n",
    "        return dec_values[CUBES_REDUCED.index(return_field[:5])], ra_values[CUBES_REDUCED.index(return_field[:5])], field_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radecPlot_2():\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    # set up the arrays to calculate the values for each field\n",
    "    ra_values = []\n",
    "    dec_values = []\n",
    "\n",
    "    for _ in range(len(CUBES)):\n",
    "        ra_values.append([])\n",
    "        dec_values.append([])\n",
    "    \n",
    "    # determine the values\n",
    "    data = np.loadtxt(CATALOGUE_KPC_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "    \n",
    "    for object in data:\n",
    "        # Determine RA and Dec for each object in the catalogue, line by line\n",
    "        field = object[FIELD_INDEX]\n",
    "        xPos = float(object[XPOS_INDEX])\n",
    "        yPos = float(object[YPOS_INDEX])\n",
    "\n",
    "        wcs = getWCS(field)\n",
    "\n",
    "        position = wcs.pixel_to_world(xPos, yPos)\n",
    "\n",
    "        ra_value = position.ra.deg\n",
    "        dec_value = position.dec.deg\n",
    "\n",
    "        field_index = CUBES.index(field)\n",
    "\n",
    "        ra_values[field_index].append(ra_value)\n",
    "        dec_values[field_index].append(dec_value)\n",
    "    \n",
    "    for i in range(len(CUBES_REDUCED)):\n",
    "        # this is the scheme to plot all of the flanking fields together\n",
    "        plt.figure()\n",
    "        plt.title(\"Celestial Coordinates of Objects in {}\".format(CUBES_REDUCED[i]))\n",
    "        for j in range(len(CUBES)):\n",
    "            if CUBES_REDUCED[i] in CUBES[j]:\n",
    "                plt.scatter(dec_values[j], ra_values[j], alpha=0.6, label=CUBES[j])\n",
    "                plt.legend()\n",
    "                plt.xlabel(\"Declination (degrees)\")\n",
    "                plt.ylabel(\"Right Ascension (degrees)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### radecHighPeculiarVelocityPlot()\n",
    "Right ascension/declination plot differentiating high velocity outliers\n",
    "\n",
    "This function inherits from: radecPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radecHighPeculiarVelocityPlot(field, pvel_cutoff=5):\n",
    "    '''\n",
    "        This function will do a radec plot but plot the objects with high peculiar velocity in a differnet colour\n",
    "\n",
    "        field (String): name of the field (eg. \"A2390C\")\n",
    "        pvel_cutoff (float): peculiar velocity cutoff point for an object to be an \"outlier\". defaults to 5\n",
    "    '''\n",
    "    decs, ras, indices = radecPlot(draw_plots=False, return_field=field)\n",
    "\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    outlier_decs = []\n",
    "    outlier_ras = []\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        entry = data[index]\n",
    "        pvel = float(entry[PVEL_INDEX])\n",
    "\n",
    "        if pvel > pvel_cutoff:\n",
    "            outlier_decs.append(decs[i])\n",
    "            outlier_ras.append(ras[i])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(decs, ras)\n",
    "    plt.scatter(outlier_decs, outlier_ras, label=\"Outliers (pvel > {})\".format(pvel_cutoff))\n",
    "    plt.title(\"ra/dec plot for {} seperated by pvel\".format(field))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Declination (degrees)\")\n",
    "    plt.ylabel(\"Right Ascension (degrees)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### radecSNPreferencePlot\n",
    "Right ascension/declination plot differentiated by signal to noise ratio preference (OIII or Hα)\n",
    "\n",
    "This function inherits from: radecPlot() and phaseDiagramBySNMagnitude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radecSNPreferencePlot(field):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    outlier_indices = phaseDiagramBySNMagnitude(draw_plots=False, return_indices=True)\n",
    "\n",
    "    decs, ras, indices = radecPlot(draw_plots=False, return_field=field)\n",
    "\n",
    "    outlier_decs = []\n",
    "    outlier_ras = []\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        if index in outlier_indices:\n",
    "            outlier_decs.append(decs[i])\n",
    "            outlier_ras.append(ras[i])\n",
    "\n",
    "    plt.scatter(decs, ras)\n",
    "    plt.scatter(outlier_decs, outlier_ras, label=\"Outliers\")\n",
    "    plt.title(\"ra/dec plot for {} seperated by S/N preference\".format(field))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Declination (degrees)\")\n",
    "    plt.ylabel(\"Right Ascension (degrees)\")\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### findOverlappingObjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOverlappingObjects(max_separation=0.001, outfile=\"overlapping_objects\"):\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    objects = []\n",
    "    # objects[i] = [field, name, ra, dec]\n",
    "\n",
    "    found = []\n",
    "    # found[i] = [field_1, name_1, field_2, name_2, dist (deg)]\n",
    "\n",
    "    for line in data:\n",
    "        # Determine RA and Dec for each object in the catalogue, line by line\n",
    "        field = line[FIELD_INDEX]\n",
    "        if field[:5] == \"A2390\" or field[:5] == \"A2465\" or field[:5] == \"RXJ21\": # Only use the clusters with multiple fields\n",
    "            name = line[NAME_INDEX]\n",
    "            xPos = float(line[XPOS_INDEX])\n",
    "            yPos = float(line[YPOS_INDEX])\n",
    "\n",
    "            wcs = getWCS(field)\n",
    "\n",
    "            position = wcs.pixel_to_world(xPos, yPos)\n",
    "\n",
    "            ra_value = position.ra.deg\n",
    "            dec_value = position.dec.deg\n",
    "\n",
    "            # Check if it is close to any previous object\n",
    "            for object in objects:\n",
    "                dra = abs(object[2] - ra_value)\n",
    "                ddec = abs(object[3] - dec_value)\n",
    "                if dra < max_separation and ddec < max_separation and field != object[0]:\n",
    "                    found.append([object[0], object[1], field, name, dra + ddec])\n",
    "                \n",
    "            objects.append([field, name, ra_value, dec_value])\n",
    "    \n",
    "    print(tabulate(found))\n",
    "    outfile = open(\"{}.txt\".format(outfile), \"w\")\n",
    "    outfile.write(tabulate(found))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### findSimilarRedshiftObjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilarRedshiftObjects(max_difference=0.01, max_separation=0.05, outfile=\"equidistant_objects.txt\"):\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    objects = []\n",
    "    # objects[i] = [field, name, z, ra, dec]\n",
    "\n",
    "    found = []\n",
    "    # found[i] = [field_1, name_1, field_2, name_2, dist (z)]\n",
    "\n",
    "    for line in data:\n",
    "        # Determine RA and Dec for each object in the catalogue, line by line\n",
    "        field = line[FIELD_INDEX]\n",
    "        if field[:5] == \"A2390\": #I only care about A2390\n",
    "            name = line[NAME_INDEX]\n",
    "            xPos = float(line[XPOS_INDEX])\n",
    "            yPos = float(line[YPOS_INDEX])\n",
    "            redshift = float(line[HAZ_INDEX])\n",
    "\n",
    "\n",
    "            wcs = getWCS(field)\n",
    "\n",
    "            position = wcs.pixel_to_world(xPos, yPos)\n",
    "\n",
    "            ra_value = position.ra.deg\n",
    "            dec_value = position.dec.deg\n",
    "\n",
    "\n",
    "            # Check if it is close to any previous object\n",
    "            for object in objects:\n",
    "                dz = abs(object[2] - redshift)\n",
    "\n",
    "                dra = abs(object[3] - ra_value)\n",
    "                ddec = abs(object[4] - dec_value)\n",
    "\n",
    "                dist = (dra**2 + ddec**2)**(1/2)\n",
    "\n",
    "                if dz < max_difference and dist < max_separation and field != object[0]:\n",
    "                    found.append([object[0], object[1], field, name, dz])\n",
    "                \n",
    "            objects.append([field, name, redshift, ra_value, dec_value])\n",
    "    \n",
    "    print(tabulate(found))\n",
    "    outfile = open(\"{}.txt\".format(outfile), \"w\")\n",
    "    outfile.write(tabulate(found))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getOutlierRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutlierRate(pvel_cutoff=3):\n",
    "    '''\n",
    "        Outputs a table that shows for each field their outlier rate\n",
    "        \"outliers\" are galaxies with peculiar velocities greater than 3 (or any other cutoff, designated by pvel_cutoff)\n",
    "        It will also print out the R200, Velocity Dispersion and total object count for each field\n",
    "    '''\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    objects = np.zeros(len[CUBES])\n",
    "    outliers = np.zeros(len[CUBES])\n",
    "\n",
    "    for object in data:\n",
    "        field = object[FIELD_INDEX]\n",
    "        pvel = float(object[PVEL_INDEX])\n",
    "\n",
    "        # determine which index to use based on the field\n",
    "        index = CUBES.index(field)\n",
    "        objects[index] += 1\n",
    "\n",
    "        if pvel >= pvel_cutoff:\n",
    "            outliers[index] += 1\n",
    "\n",
    "    rates = (outliers / objects).round(decimals=3)\n",
    "    objects = objects.astype(int)\n",
    "    outliers = outliers.astype(int)\n",
    "    \n",
    "    print(tabulate([CUBES, R200S, DISPERSIONS, objects, outliers, rates], tablefmt=\"simple_grid\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(cluster=\"A2390C\", depth=10000, bucket_size=0.02, max_r200=2):\n",
    "    '''\n",
    "        Determines the coverage of a given cluster by radius out to 2R200\n",
    "        This function is simpler but less complete than coverage_2(). This function cannot do the multi-field clusters like A2390, but, it doesn't need to read in the header files.\n",
    "\n",
    "        How it works:\n",
    "        for each radius outwards, generate a 1000 points within that distance. Find out how many are within the image and calculate coverage rate\n",
    "        \n",
    "        cluster (String): chosen cluster (eg. \"A2390C\")\n",
    "        depth (int): number of points to throw in the monte carlo simulation\n",
    "    '''\n",
    "    \n",
    "    bcg = BCGS[cluster[:5]][0]\n",
    "    bcg_location = radecToPix(bcg, cluster)\n",
    "    bcg_x = bcg_location[0]\n",
    "    bcg_y = bcg_location[1]\n",
    "    \n",
    "    r200 = R200S_REDUCED[CUBES_REDUCED.index(cluster[:5])]\n",
    "\n",
    "    #intervals of 5% r200\n",
    "    dist_multipliers = np.arange(0, max_r200, bucket_size)\n",
    "    dist_kpcs = dist_multipliers * r200\n",
    "    dist_pixs = kpcToPix(dist_kpcs, cluster)\n",
    "    \n",
    "    ratios = []\n",
    "    \n",
    "    for dist_cutoff in dist_pixs:\n",
    "        within_count = 0\n",
    "\n",
    "        for point in range(depth):\n",
    "            dx = np.random.rand() * dist_cutoff\n",
    "            dy = np.random.rand() * dist_cutoff\n",
    "            \n",
    "            point_x = bcg_x + dx\n",
    "            point_y = bcg_y + dy\n",
    "\n",
    "            within_image = (point_x > 0 and point_y > 0 and point_x < 2064 and point_y < 2048)\n",
    "\n",
    "            if within_image:\n",
    "                within_count += 1\n",
    "            \n",
    "        ratios.append(within_count / depth)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(dist_multipliers, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_stripped(cluster=\"A2390C\", depth=10000, bucket_size=0.02, max_r200=2):\n",
    "    bcg_location = radecToPix(BCGS[cluster[:5]][0], cluster)\n",
    "    dist_multipliers = np.arange(0, max_r200, bucket_size)\n",
    "    ratios = []\n",
    "    for dist_cutoff in kpcToPix(dist_multipliers * R200S_REDUCED[CUBES_REDUCED.index(cluster[:5])], cluster):\n",
    "        within_count = 0\n",
    "        for _ in range(depth):\n",
    "            point_x = bcg_location[0] + np.random.rand() * dist_cutoff\n",
    "            point_y = bcg_location[1] + np.random.rand() * dist_cutoff\n",
    "            if (point_x > 0 and point_y > 0 and point_x < 2064 and point_y < 2048): within_count+=1\n",
    "        ratios.append(within_count / depth)\n",
    "    plt.figure()\n",
    "    plt.plot(dist_multipliers, ratios)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coverage_2()\n",
    "Just like coverage(), except it can do multi-field clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxRadec(field=\"A2390C\"):\n",
    "    # min ra, min dec, max ra, max dec\n",
    "    radec_mins = pixToRadec((0,0), field)\n",
    "    radec_maxs = pixToRadec((2064,2048), field)\n",
    "\n",
    "    return np.min([radec_mins[0], radec_maxs[0]]), np.min([radec_mins[1], radec_maxs[1]]), np.max([radec_mins[0], radec_maxs[0]]), np.max([radec_mins[1], radec_maxs[1]])\n",
    "\n",
    "def coverage_2(cube=\"A2390\", depth=10000, bucket_size=0.02, max_r200=2):\n",
    "    fields = []\n",
    "    extremas = []\n",
    "    for field in CUBES:\n",
    "        if cube in field:\n",
    "            fields.append(field)\n",
    "            extremas.append(minmaxRadec(field))\n",
    "\n",
    "    bcg = BCGS[cube[:5]][0]\n",
    "    bcg_ra = bcg[0]\n",
    "    bcg_dec = bcg[1]\n",
    "    \n",
    "    r200 = R200S_REDUCED[CUBES_REDUCED.index(cube[:5])]\n",
    "    r200_deg = np.rad2deg(kpcToRad(r200, fields[0]))\n",
    "    #intervals of 5% r200\n",
    "    dist_multipliers = np.arange(0, max_r200, bucket_size)\n",
    "    dist_degs = dist_multipliers * r200_deg\n",
    "    \n",
    "    ratios = []\n",
    "    \n",
    "    offsets = ( np.random.rand(depth, 2) * 2 ) - 1\n",
    "\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "\n",
    "    success_x = []\n",
    "    success_y = []\n",
    "\n",
    "    for dist_cutoff in dist_degs:\n",
    "        within_count = 0\n",
    "\n",
    "        for offset in offsets:\n",
    "            dra = offset[0] * dist_cutoff\n",
    "            dec_max = np.sqrt(dist_cutoff**2 - dra**2)\n",
    "            ddec = offset[1] * dec_max\n",
    "            \n",
    "            point_ra = bcg_ra + dra\n",
    "            point_dec = bcg_dec + ddec\n",
    "\n",
    "            all_x.append(point_ra)\n",
    "            all_y.append(point_dec)\n",
    "\n",
    "            for extrema in extremas:\n",
    "                if (point_ra > extrema[0] and point_dec > extrema[1] and point_ra < extrema[2] and point_dec < extrema[3]):\n",
    "                    within_count += 1\n",
    "                    break\n",
    "                    success_x.append(point_ra)\n",
    "                    success_y.append(point_dec)\n",
    "            \n",
    "        ratios.append(within_count / depth)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(dist_multipliers, ratios)\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.scatter(all_x, all_y, color=\"red\")\n",
    "    #plt.scatter(success_x, success_y, color=\"blue\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pullToFolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def pullToFolder(infile_path, inimage_path, outfolder_name, field_index=0, name_index=1, delimiter=\" \"):\n",
    "    '''\n",
    "        This function takes in a path for a catalog of objects, and a folder that contains images of those objects (among others). \n",
    "        It will pull the images corresponding to the objects in the catalogue into a destination folder.\n",
    "\n",
    "        The catalog must have a column for the field, and a column for the name. Something like this: A2390 1797 \n",
    "        You can set whatever indices you need for those two, and the delimiter.\n",
    "\n",
    "        infile_path (String): path of catalog with field and object names\n",
    "        inimage_path (String): path of folder with images to pull from\n",
    "        outfolder_name (String): destination folder\n",
    "\n",
    "        field_index=0 (int)\n",
    "        name_index=1 (int)\n",
    "        delimiter=\" \" (String)\n",
    "    '''\n",
    "    outFolder = \"./\" + outfolder_name\n",
    "\n",
    "    try:\n",
    "        os.mkdir(outFolder)\n",
    "    except:\n",
    "        print(\"Folder already exists\")\n",
    "\n",
    "    lines = np.loadtxt(infile_path, skiprows=1, delimiter=delimiter, dtype=\"str\")\n",
    "\n",
    "    for line in lines:\n",
    "        field = line[field_index]\n",
    "        name = line[name_index]\n",
    "\n",
    "        files = os.listdir(inimage_path + \"/\" + field)\n",
    "\n",
    "        for file in files:\n",
    "            # the files are named field#name.png\n",
    "            splitfile = file.split(\"#\")\n",
    "            if splitfile[1][:-4] == name:\n",
    "                shutil.copy2(inimage_path + \"/\" + field + \"/\" + file, outFolder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collectFarOIIIObjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectFarOIIIObjects(outfile_path=\"farOIIIObjects.txt\", min_r200=1):\n",
    "    '''\n",
    "        This functions collects objects from all fields with OIII S/N preference far from the cluster center\n",
    "\n",
    "        min_r200=1 (float): how many r200s to start collecting objects from\n",
    "    '''\n",
    "\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    output = \"\"\n",
    "\n",
    "    for object in data:\n",
    "        SN_Ha = float(object[HASN_INDEX])\n",
    "        SN_OIII = float(object[OTSN_INDEX])\n",
    "        dist = float(object[DIST_INDEX])\n",
    "\n",
    "        if dist > min_r200 and SN_OIII > SN_Ha:\n",
    "            output = output + \"\\n\" + \" \".join(object)\n",
    "    \n",
    "    outfile = open(outfile_path, \"w\")\n",
    "    outfile.write(output)\n",
    "    outfile.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### highNegativePvels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highNegativePvels(cutoff=3):\n",
    "    data = np.loadtxt(CATALOGUE_PHASE_PATH, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    flagged_objects = []\n",
    "\n",
    "    for object in data:\n",
    "        field = object[FIELD_INDEX]\n",
    "        name = object[NAME_INDEX]\n",
    "        pvel = float(object[PVEL_INDEX])\n",
    "\n",
    "        if pvel < 0 and abs(pvel) > cutoff:\n",
    "            flagged_objects.append([field, name, pvel])\n",
    "    \n",
    "    print(tabulate(flagged_objects))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalogues and working with fits files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing headers example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "'''\n",
    "    This function takes a list of header entries in one header and moves them to another\n",
    "'''\n",
    "\n",
    "def changeHeader():\n",
    "    FIELD = \"A2390NW\"\n",
    "    THINGS_TO_CHANGE = [\"CTYPE1\", \"CTYPE2\", \"CRVAL1\", \"CRPIX1\", \"CRVAL2\", \"CRPIX2\"]\n",
    "\n",
    "    source_fits = \"E:/SITELLE/AstroResearch/{}/{}.fits\".format(FIELD, FIELD)\n",
    "    target_fits = \"E:/SITELLE/AstroResearch/{}/{}.deep_frame.fits\".format(FIELD, FIELD)\n",
    "\n",
    "    hdul = fits.open(source_fits, mode='readonly', memmap=False) # open source fits file\n",
    "    source_header = hdul[0].header # get the header\n",
    "\n",
    "    for header_entry in THINGS_TO_CHANGE:\n",
    "        fits.setval(target_fits, header_entry, value=source_header[header_entry])  # set the values using fits.setval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### createCatalogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def createCatalogue(elg_lists_path, SITELLE_path):\n",
    "    '''\n",
    "        This script takes all the redshift, R, S/N fits from all the templates in Qing's SITELLE_ELG_Finder\n",
    "        extracts them from the pickle file and creates a catalogue\n",
    "        \n",
    "            1        2       3        4        5       6       7               8       9       10        11        12        13          14       15       16\n",
    "    '''\n",
    "    labels = [\"field\", \"name\", \"x_loc\", \"y_loc\", \"eq_r\", \"flag\", \"rad_dist_BCG\", \"Ha_z\", \"Ha_R\", \"Ha_S/N\", \"OIII_z\", \"OIII_R\", \"OIII_S/N\", \"OII_z\", \"OII_R\", \"OII_S/N\"]\n",
    "    # Write top line of file\n",
    "    outlabel = \" \".join(labels)\n",
    "    outfile = open(\"Catalogue.txt\", \"w\")\n",
    "    outfile.write(outlabel)\n",
    "\n",
    "    path = elg_lists_path + \"/\"\n",
    "    ending = \"_ELG_list.txt\"\n",
    "\n",
    "    for field in CUBES:\n",
    "        infile = open(\"{}/{}/{}/{}-cc-MMA_lpf.pkl\".format(SITELLE_path, field, field, field), 'rb')\n",
    "        pickle_dict = pickle.load(infile)\n",
    "        infile.close()\n",
    "\n",
    "        lines = np.loadtxt(\"{}{}{}\".format(path, field, ending), skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "        for line in lines:\n",
    "            output = []\n",
    "\n",
    "            name = line[0]\n",
    "            x_loc = line[1]\n",
    "            y_loc = line[2]\n",
    "            \n",
    "            output.append(field) # field\n",
    "            output.append(name) # name\n",
    "            output.append(x_loc)\n",
    "            output.append(y_loc)\n",
    "            output.append(line[5]) # eq_r\n",
    "            output.append(line[10]) # flag\n",
    "\n",
    "            output.append(pickle_dict['Ha-NII_gauss'][name]['z_best']) #Ha_z\n",
    "            output.append(pickle_dict['Ha-NII_gauss'][name]['R']) #Ha_R\n",
    "            output.append(pickle_dict['Ha-NII_gauss'][name]['SNR']) #Ha_S/N\n",
    "\n",
    "            output.append(pickle_dict['Hb-OIII_gauss'][name]['z_best']) #OIII_z\n",
    "            output.append(pickle_dict['Hb-OIII_gauss'][name]['R']) #OIII_R\n",
    "            output.append(pickle_dict['Hb-OIII_gauss'][name]['SNR']) #OIII_S/N\n",
    "\n",
    "            output.append(pickle_dict['OII_gauss'][name]['z_best']) #OII_z\n",
    "            output.append(pickle_dict['OII_gauss'][name]['R']) #OII_R\n",
    "            output.append(pickle_dict['OII_gauss'][name]['SNR']) #OII_S/N\n",
    "\n",
    "            outfile.write(\"\\n\")\n",
    "            outfile.write(\" \".join(map(str, output)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region file example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_numb(number, elements, tarmin, tarmax):\n",
    "    '''\n",
    "        This function maps a number based on what percentile it is in a set\n",
    "        for example: map the object of the 70th percentile onto (0, 255), it would have a value of 0.7 x 255 = 178.5\n",
    "        this is used to create the colour distance gradient for createRegionFile()\n",
    "    '''\n",
    "    greatercount = 1\n",
    "    lessercount = 1\n",
    "    for item in elements:\n",
    "        if number >= item:\n",
    "            greatercount += 1\n",
    "        else:\n",
    "            lessercount += 1\n",
    "\n",
    "    percentile = (greatercount) / (lessercount + greatercount)\n",
    "    \n",
    "    mapped_number = 255 * percentile\n",
    "    \n",
    "    return mapped_number\n",
    "\n",
    "def createRegionFile(filename=\"catalogue_dist_rad.txt\", field=\"A2390C\", delimiter=\" \", xindex=2, yindex=3, distindex=15, circlesize=5):\n",
    "    '''\n",
    "        This script will create a .txt file containing regions for each object in a given cluster\n",
    "        Each region will be a different grayscale colour based on percentile distance. black=close, white=far\n",
    "    '''\n",
    "\n",
    "    COLORMIN = 000\n",
    "    COLORMAX = 255\n",
    "\n",
    "    lines = np.loadtxt(filename, skiprows=1, delimiter=delimiter, dtype=\"str\")\n",
    "\n",
    "    xLocs = []\n",
    "    yLocs = []\n",
    "    dists = []\n",
    "\n",
    "    # get position of each object and distance from BCG\n",
    "    for line in lines:\n",
    "        fieldname = line[0]\n",
    "        \n",
    "        if fieldname == field:\n",
    "            xLocs.append(line[xindex])\n",
    "            yLocs.append(line[yindex])\n",
    "            dists.append(float(line[distindex]))\n",
    "    \n",
    "    # open output file and write global information\n",
    "    outfile = open(\"regions_by_distance_{}.reg\".format(field), \"w\")\n",
    "    outfile.write(\"global width=8\\nIMAGE\\n\")\n",
    "    \n",
    "    # write in the circle for each object\n",
    "    for i in range(len(xLocs)):\n",
    "        # get the colour in the gradient\n",
    "        mapped_color = int(map_numb(dists[i], dists, COLORMIN, COLORMAX)) #This generates a number 0-255, a grayscale colour\n",
    "        \n",
    "        # convert the colour to hex (RGB somehow doesn't work)\n",
    "        color = str(hex(mapped_color))[2:] * 3\n",
    "\n",
    "        # write in the circle for the object\n",
    "        outfile.write(\"circle({},{},{}) # color=#{}\\n\".format(xLocs[i], yLocs[i], str(circlesize), color))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WCS and wcs.pixel_to_world test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelWorldComparison(field=\"A2390C\", catalogue_path=\"catalogue_dist_rad.txt\"):\n",
    "    '''\n",
    "        This script will take each galaxy identified by Qing's code, use WCS to get the ra/dec position, then create a region file to be drawn in DS9\n",
    "        This is done to check if the WCS or pixel_to_world is being problematic\n",
    "    '''\n",
    "\n",
    "    SIZE = 5\n",
    "\n",
    "    wcs = getWCS(field)\n",
    "\n",
    "    data = np.loadtxt(catalogue_path, skiprows=1, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "    x_locations = []\n",
    "    y_locations = []\n",
    "    ra_positions = []\n",
    "    dec_positions = []\n",
    "\n",
    "    for object in data:\n",
    "        field = object[FIELD_INDEX]\n",
    "        if field == \"A2390C\":\n",
    "            xLoc = float(object[XPOS_INDEX])\n",
    "            yLoc = float(object[YPOS_INDEX])\n",
    "\n",
    "            x_locations.append(xLoc)\n",
    "            y_locations.append(yLoc)\n",
    "\n",
    "            target_1 = wcs.pixel_to_world(xLoc, yLoc)\n",
    "\n",
    "            ra_positions.append(target_1.ra.deg)\n",
    "            dec_positions.append(target_1.dec.deg)\n",
    "\n",
    "    cartesian_reg = open(\"{}_cartesian_positions.reg\".format(field), \"w\")\n",
    "    cartesian_reg.write(\"global width=8 color=green\\nIMAGE\")\n",
    "\n",
    "    skycoords_reg = open(\"{}_skycoods_positions.reg\".format(field), \"w\")\n",
    "    skycoords_reg.write(\"global width=8 color=red\\nFK5\")\n",
    "\n",
    "    for i in range(len(x_locations)):\n",
    "        cartesian_reg.write(\"\\ncircle({},{},{})\".format(x_locations[i], y_locations[i], SIZE))\n",
    "        skycoords_reg.write(\"\\ncircle({},{},2\\\")\".format(ra_positions[i], dec_positions[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### appendColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendColumns(path=\"E:\\Summer Project 2022\\ELG_Lists\\A2390C_ELG_list.txt\", count=1, position=None):\n",
    "    '''\n",
    "        This function takes in a catalogue and appends 0s to fill columns\n",
    "\n",
    "        position=None (int): which column to append after (if you want to append 0s in between columns). none means append to end.\n",
    "    '''\n",
    "\n",
    "    # open and read in the catalogue\n",
    "    infile = open(path, \"r\")\n",
    "    lines = infile.readlines()\n",
    "    infile.close()\n",
    "\n",
    "    # create a new one THIS MAKES THE CODE DANGEROUS\n",
    "    outfile = open(path, \"w\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        outline = \"\"\n",
    "\n",
    "        # add each line back into the output\n",
    "        for i, word in enumerate(line):\n",
    "            word = word.strip()\n",
    "            outline += word + \" \"\n",
    "\n",
    "            # if you're using the positon, check if you're in the right position\n",
    "            if position is not None:\n",
    "                if i == position:\n",
    "                    for _ in range(count):\n",
    "                        outline += \"0 \"\n",
    "        # if not using position, add to the end\n",
    "        if position is None:\n",
    "            for _ in range(count):\n",
    "                outline += \"0 \"\n",
    "                    \n",
    "        outline += \"\\n\"\n",
    "        outfile.write(outline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run your code here\n",
    "Call the functions you need, and further manipulations that you want to make, in this code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Use this cell to run your code\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Use this cell to run your code\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cbc60077ec164c69899806146a460b44edb65ff201bf8fff4c399e895f7e401"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
